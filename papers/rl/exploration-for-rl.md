## Exploration for RL

[2023] [Action Noise in Off-Policy Deep Reinforcement Learning: Impact on Exploration and Performance](https://arxiv.org/abs/2206.03787)

[2024] [The Limits of Pure Exploration in POMDPs: When the Observation Entropy is Enough](https://arxiv.org/abs/2406.12795)



### Methods

[2016] [#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning](https://arxiv.org/abs/1611.04717)

[2017] [Parameter Space Noise for Exploration](https://arxiv.org/abs/1706.01905#)

[2017] [Curiosity-driven Exploration by Self-supervised Prediction](https://arxiv.org/abs/1705.05363)

[2018] [Count-Based Exploration with the Successor Representation](https://arxiv.org/abs/1807.11622)

[2018] [Provably Efficient Maximum Entropy Exploration](https://arxiv.org/abs/1812.02690)

[2021] [State Entropy Maximization with Random Encoders for Efficient Exploration](https://arxiv.org/abs/2102.09430)

[2022] [Action Noise in Off-Policy Deep Reinforcement Learning: Impact on Exploration and Performance](https://arxiv.org/abs/2206.03787)

[2023] [Colored Noise in PPO: Improved Exploration and Performance through Correlated Action Sampling](https://arxiv.org/abs/2312.11091)

[2023] [Latent Exploration for Reinforcement Learning](https://arxiv.org/abs/2305.20065)

[2023] [Pink Noise Is All You Need: Colored Noise Exploration in Deep Reinforcement Learning](https://openreview.net/pdf?id=hQ9V5QN27eS) 

[2023] [DEP-RL: Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems](https://arxiv.org/abs/2206.00484)

[2024] [Latent Space Exploration and Trajectory Space Update in Temporally-Correlated Episodic Reinforcement Learning](https://openreview.net/pdf?id=e8dcuniLcA)

[2024] [More Efficient Randomized Exploration for Reinforcement Learning via Approximate Sampling](https://arxiv.org/abs/2406.12241)