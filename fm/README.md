# Foundation Model

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re) [![MIT License](https://img.shields.io/badge/license-MIT-green.svg)](https://opensource.org/licenses/MIT) [![LICENSE](https://img.shields.io/badge/license-Anti%20996-blue.svg)](https://github.com/996icu/996.ICU/blob/master/LICENSE)

Papers, codes, datasets, tasks, applications, tutorials.

**Widely used by top conferences, journals and workshops:**

- Conferences: [[ICML](https://icml.cc/)] [[CVPR](https://cvpr.thecvf.com/)] 
- Workshops: : [[MFM-EAI](https://icml-mfm-eai.github.io/)] [[Embodied-AI](https://embodied-ai.org/)]



## 0.Survey

[2021] [On the Opportunities and Risks of Foundation Models](https://arxiv.org/abs/2108.07258)

[2023] [Large language models for humanâ€“robot interaction: A review](https://www.sciencedirect.com/science/article/pii/S2667379723000451)

[2023] [Foundation Models in Robotics: Applications, Challenges, and the Future](https://arxiv.org/abs/2312.07843)

[2023] [Robot Learning in the Era of Foundation Models: A Survey](https://arxiv.org/abs/2311.14379)

[2023] [Toward General-Purpose Robots via Foundation Models: A Survey and Meta-Analysis](https://arxiv.org/abs/2312.08782)

[2023] [Foundation Models for Decision Making: Problems, Methods, and Opportunities](https://arxiv.org/abs/2303.04129)

[2024] [Large Language Models for Robotics: Opportunities, Challenges, and Perspectives](https://arxiv.org/abs/2401.04334)

[2024] [Real-World Robot Applications of Foundation Models: A Review](https://arxiv.org/abs/2402.05741)

[2024] [A Survey on Vision-Language-Action Models for Embodied AI](https://arxiv.org/abs/2405.14093)

[2024] [Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI](https://arxiv.org/abs/2407.06886)

:speaker: ***If you would like some specific areas' survey, such as  multimodal large model, large language model, and etc, please click related links in part one.***



## 1.Research Areas and Papers

:speaker: ***There are just some pretty papers for beginners and interested figures.***

- [Embodied AI](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/eai)

---

- [Generative AI and its Application](https://github.com/Evan-wyl/robotlearning/tree/master/fm/papers/generative-ai-and-application)
- [Large Language Model and its Application](https://github.com/Evan-wyl/robotlearning/tree/master/fm/papers/llm-and-application)
- [Multi-Modal Large Model and its Application](https://github.com/Evan-wyl/robotlearning/tree/master/fm/papers/mmlm-and-application)
- [World Model and its Application](https://github.com/Evan-wyl/robotlearning/tree/master/fm/papers/world-models-and-application)

---

- [Robotic Transformer](https://github.com/Evan-wyl/robotlearning/tree/master/fm/papers/robotic-transformer)
- [Vision Language Action Model](https://github.com/Evan-wyl/robotlearning/tree/master/fm/papers/vision-language-action)
- [Learning from Video](https://github.com/Evan-wyl/robotlearning/blob/master/fm/papers/learning-from-video.md)

---

- [Vision Foundation Model](https://github.com/Evan-wyl/robotlearning/blob/master/fm/papers/vision-foundation-model.md)
- [Navigation](https://github.com/Evan-wyl/robotlearning/blob/master/fm/papers/navigation.md)

---

- [Theory](https://github.com/Evan-wyl/robotlearning/blob/master/fm/papers/theory)



## 2.Datasets and Benchmarks

Please see [Here](https://github.com/Evan-wyl/Robot-Learning/tree/master/fm/data) for the popular robot learning **datasets, simulator and benchmark** results.



## 3.Relevant Resources

Please see [HERE](https://github.com/Evan-wyl/Robot-Learning/tree/master/docs/resources.md) for some awesome relevant resources, such as

- Awesome Repository, including Large Model inference and evaluation.

------

***Copyright notice***

> ***[Notes]This Github repo can be used by following the corresponding licenses. I want to emphasis that it may contain some PDFs or thesis, which were downloaded by me and can only be used for academic purposes. The copyrights of these materials are owned by corresponding publishers or organizations. All this are for better adademic research. If any of the authors or publishers have concerns, please contact me to delete or replace them.***