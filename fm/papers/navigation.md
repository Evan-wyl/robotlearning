## Navigation

### Survey

[2024] [Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models](https://arxiv.org/abs/2407.07035)



### Algorithms

[2024] [PoliFormer: Scaling On-Policy RL with Transformers Results in Masterful Navigators](https://arxiv.org/abs/2406.20083)

[2024] [Visual-Geometry GP-based Navigable Space for Autonomous Navigation](https://arxiv.org/abs/2407.06545)

[2024] [Fast-Slow Test-Time Adaptation for Online Vision-and-Language Navigation](https://openreview.net/pdf?id=Zos5wsaB5r)

[2024] [Neural Control Barrier Functions for Safe Navigation](https://arxiv.org/abs/2407.19907)

[2024] [TrustNavGPT: Modeling Uncertainty to Improve Trustworthiness of Audio-Guided LLM-Based Robot Navigation](https://arxiv.org/abs/2408.01867)



### Vision and Language Navigation

[2021] [Episodic Transformer for Vision-and-Language Navigation](https://arxiv.org/abs/2105.06453)

[2024] [NavGPT-2: Unleashing Navigational Reasoning Capability for Large Vision-Language Models](https://arxiv.org/abs/2407.12366)

[2024] [Navigating Beyond Instructions: Vision-and-Language Navigation in Obstructed Environments](https://arxiv.org/abs/2407.21452)

[2024] [ET tu, CLIP? Addressing Common Object Errors for Unseen Environments](https://arxiv.org/abs/2406.17876)

[2024] [NaVILA: Legged Robot Vision-Language-Action Model for Navigation](https://arxiv.org/abs/2412.04453)



### Offline RL and RL

[2023] [GNM: A General Navigation Model to Drive Any Robot](https://sites.google.com/view/drive-any-robot)