## Algorithms

[2021] [ReduNet: A White-box Deep Network from the Principle of Maximizing Rate Reduction](https://arxiv.org/abs/2105.10446)

[2022] [Incremental Learning of Structured Memory via Closed-Loop Transcription](https://arxiv.org/abs/2202.05411)

[2022] [Unsupervised Learning of Structured Representations via Closed-Loop Transcription](https://arxiv.org/abs/2210.16782)

[2023] [White-Box Transformers via Sparse Rate Reduction: Compression Is All There Is?](https://arxiv.org/abs/2311.13110)

[2023] [White-Box Transformers via Sparse Rate Reduction](https://arxiv.org/abs/2306.01129)

[2024] [Scaling White-Box Transformers for Vision](https://arxiv.org/abs/2405.20299)

